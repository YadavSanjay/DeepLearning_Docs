{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token_to_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b2e1a2fb68cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mto_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnames_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'token_to_id' is not defined"
     ]
    }
   ],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        #print(name_ix)\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "        #if i < 10:\n",
    "            #print(name_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \"X\"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      "XAbagael\n",
      "XClaresta\n",
      "XGlory\n",
      "XLiliane\n",
      "XPrissie\n",
      "XGeeta\n",
      "XGiovanne\n",
      "XPiggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2d6e75390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = set()### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "for name in names:\n",
    "    for char in name:\n",
    "        tokens.add(char)\n",
    "tokens.add(pad_token)\n",
    "        \n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "collapsed": true
   },
   "source": [
    "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "for token in tokens:\n",
    "    token_to_id[token]=tokens.index(token)\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its index in tokens} for token in tokens: token_to_id[token]=tokens.index(token)\n",
    "for token in tokens:\n",
    "    token_to_id[token] = tokens.index(token)\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        #print(name_ix)\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "        #if i < 10:\n",
    "            #print(name_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XAbagael\n",
      "XGlory\n",
      "XPrissie\n",
      "XGiovanne\n",
      "[[50  2 54 40  1 40 48  7 39]\n",
      " [50 12  7 47  0 23 39 39 39]\n",
      " [50 51  0 11 42 42 11 48 39]\n",
      " [50 12 11 47 24 40 46 46 48]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units)### YOUR CODE HERE\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens,activation=\"softmax\")### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb,h_t])### YOUR CODE HERE\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix,predictions_matrix)) ### YOUR CODE HERE\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nu9gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa2aabddb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XBachey\n",
      "XKoly\n",
      "XSdarra\n",
      "XCybere\n",
      "XLigely\n",
      "XAlatA\n",
      "XFhary\n",
      "XBanry\n",
      "XKariin\n",
      "XKerina\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpi\n",
      " Trumpys\n",
      " Trumpan\n",
      " Trumpori\n",
      " Trumpachre\n",
      " Trumpelsenena\n",
      " Trumprel\n",
      " Trumphialra\n",
      " Trumpidgio\n",
      " Trumpari\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
    "COURSERA_EMAIL = \"### YOUR EMAIL HERE ###\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
